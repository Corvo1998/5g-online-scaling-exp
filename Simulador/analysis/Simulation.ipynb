{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "48a893cc",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "import os\n",
    "import re"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "8ac527e6",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Diretórios\n",
    "folder = '../output/'\n",
    "output_dir = 'figures_metrics'\n",
    "os.makedirs(output_dir, exist_ok=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "d30e4493",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Mapeamento de rótulos para nomes amigáveis\n",
    "modelo_nomes = {\n",
    "    'BLR': 'Bayesian Linear Regressor',\n",
    "    'EWA': 'EWARegressor',\n",
    "    'KNN': 'KNNRegressor',\n",
    "    'SKL': 'Scikit-Learn Regressor',\n",
    "    'SRP': 'SRPRegressor'\n",
    "    # adicione mais se quiser\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "66f0eb95",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Modelos detectados: ['BLR', 'EWA', 'KNN', 'SKL', 'SRP']\n"
     ]
    }
   ],
   "source": [
    "# Detectar modelos presentes nos arquivos\n",
    "arquivos_modelo = [f for f in os.listdir(folder) if not f.startswith('Ideal_') and f.endswith('.csv')]\n",
    "modelos_detectados = sorted(set(re.match(r'^([A-Za-z0-9_]+)_\\d+_', f).group(1) for f in arquivos_modelo if re.match(r'^([A-Za-z0-9_]+)_\\d+_', f)))\n",
    "print(\"Modelos detectados:\", modelos_detectados)\n",
    "\n",
    "# Detectar intervalos de cluster\n",
    "ideal_files = [f for f in os.listdir(folder) if f.startswith('Ideal_') and f.endswith('.csv')]\n",
    "i_range = sorted({int(re.search(r'_(\\d+)', f).group(1)) for f in ideal_files})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "379ec71c",
   "metadata": {},
   "outputs": [],
   "source": [
    "file_config = {\n",
    "    \"unallocated_requests\": {\n",
    "        \"column_y\": \"Unallocated Requests\"\n",
    "    },\n",
    "    \"active_amfs\": {\n",
    "        \"column_y\": \"Active AMFs\"\n",
    "    },\n",
    "    \"amf_utilization\": {\n",
    "        \"column_y\": \"AMF Utilization (%)\"\n",
    "    }\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "be723d6e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Métricas salvas em: figures_metrics/metrics_summary_with_ideal.csv\n"
     ]
    }
   ],
   "source": [
    "def calculate_metrics_with_ideal(file_config, i_range):\n",
    "    summary = []\n",
    "\n",
    "    for key, config in file_config.items():\n",
    "        for i in i_range:\n",
    "            csv_files = {\n",
    "                \"ideal\": os.path.join(folder, f\"Ideal_{i}_{key}.csv\".replace(\"active_amfs\", \"active_amfs_log\"))\n",
    "            }\n",
    "\n",
    "            for model in modelos_detectados:\n",
    "                model_path = os.path.join(folder, f\"{model}_{i}_{key}.csv\".replace(\"active_amfs\", \"active_amfs_log\"))\n",
    "                csv_files[model] = model_path\n",
    "\n",
    "            data_frames = {}\n",
    "            for label, path in csv_files.items():\n",
    "                if not os.path.exists(path):\n",
    "                    print(f\"[Aviso] Arquivo não encontrado: {path}\")\n",
    "                    continue\n",
    "\n",
    "                df = pd.read_csv(path)\n",
    "                if config[\"column_y\"] not in df.columns:\n",
    "                    print(f\"[Erro] Coluna '{config['column_y']}' ausente em {path}\")\n",
    "                    continue\n",
    "\n",
    "                data_frames[label] = df\n",
    "\n",
    "            if len(data_frames) < len(modelos_detectados) + 1:\n",
    "                print(f\"[Pular] Cluster {i}: dados incompletos para '{key}'\")\n",
    "                continue\n",
    "\n",
    "            ideal_sum = data_frames[\"ideal\"][config[\"column_y\"]].sum()\n",
    "\n",
    "            for label, df in data_frames.items():\n",
    "                if label == \"ideal\":\n",
    "                    continue\n",
    "\n",
    "                total = df[config[\"column_y\"]].sum()\n",
    "                average = df[config[\"column_y\"]].mean()\n",
    "                max_val = df[config[\"column_y\"]].max()\n",
    "                deviation = total - ideal_sum\n",
    "                deviation_pct = (deviation / ideal_sum) * 100 if ideal_sum != 0 else None\n",
    "\n",
    "                summary.append({\n",
    "                    \"Cluster\": i,\n",
    "                    \"Metric\": key,\n",
    "                    \"Model\": modelo_nomes.get(label, label),\n",
    "                    \"Total\": total,\n",
    "                    \"Average\": average,\n",
    "                    \"Max\": max_val,\n",
    "                    \"Ideal Total\": ideal_sum,\n",
    "                    \"Deviation\": deviation,\n",
    "                    \"Deviation (%)\": deviation_pct\n",
    "                })\n",
    "\n",
    "    return pd.DataFrame(summary)\n",
    "\n",
    "# Executar e salvar\n",
    "metrics_summary = calculate_metrics_with_ideal(file_config, i_range)\n",
    "summary_path = os.path.join(output_dir, \"metrics_summary_with_ideal.csv\")\n",
    "metrics_summary.to_csv(summary_path, index=False)\n",
    "print(f\"Métricas salvas em: {summary_path}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0dd98ba1",
   "metadata": {},
   "source": [
    "Atendidas"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "15d5e90f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Modelos detectados: ['BLR', 'EWA', 'Ideal', 'KNN', 'SKL', 'SRP']\n",
      "Clusters detectados: [0, 1, 2, 3, 4]\n",
      "\n",
      "✅ Gráficos salvos em 'figures_attended' e tabela de perdas salva em:\n",
      "→ figures_attended/tabela_requisicoes_perdidas_por_cluster.csv\n"
     ]
    }
   ],
   "source": [
    "# Diretórios\n",
    "folder = '../output/'\n",
    "output_folder = 'figures_attended'\n",
    "os.makedirs(output_folder, exist_ok=True)\n",
    "\n",
    "# Detecta automaticamente os modelos disponíveis\n",
    "arquivos = os.listdir(folder)\n",
    "modelo_pattern = re.compile(r\"^([A-Za-z0-9_]+)_\\d+_unallocated_requests\\.csv$\")\n",
    "modelos = sorted({match.group(1) for f in arquivos if (match := modelo_pattern.match(f))})\n",
    "print(\"Modelos detectados:\", modelos)\n",
    "\n",
    "# Rótulos opcionais para exibição\n",
    "modelo_nomes = {\n",
    "    'BLR': 'Bayesian Linear Regressor',\n",
    "    'EWA': 'EWARegressor',\n",
    "    # outros modelos aqui, se quiser\n",
    "}\n",
    "rotulos = [modelo_nomes.get(m, m) for m in modelos]\n",
    "\n",
    "# Intervalo de experimentos baseado nos arquivos\n",
    "exp_nums = sorted({int(re.search(r'_(\\d+)_', f).group(1)) for f in arquivos if 'unallocated_requests.csv' in f})\n",
    "print(\"Clusters detectados:\", exp_nums)\n",
    "\n",
    "# Tempo\n",
    "start_time = pd.to_datetime(\"2013-12-01 00:00\")\n",
    "freq = \"10min\"\n",
    "\n",
    "# Total de perdas para tabela final\n",
    "tabela_perdas = []\n",
    "\n",
    "def extract_total_requests(log_path):\n",
    "    totals = []\n",
    "    with open(log_path, 'r') as f:\n",
    "        for line in f:\n",
    "            if line.startswith(\"Time\"):\n",
    "                match = re.search(r'Total Requests: (\\d+)', line)\n",
    "                if match:\n",
    "                    totals.append(int(match.group(1)))\n",
    "    return pd.Series(totals)\n",
    "\n",
    "def plot_attended_comparison(exp_num):\n",
    "    dfs_unallocated = {}\n",
    "    dfs_total = {}\n",
    "    time_index = None\n",
    "\n",
    "    for modelo in modelos:\n",
    "        unallocated_file = f'{folder}{modelo}_{exp_num}_unallocated_requests.csv'\n",
    "        log_file = f'{folder}{modelo}_{exp_num}_states_log.txt'\n",
    "\n",
    "        if not os.path.exists(unallocated_file) or not os.path.exists(log_file):\n",
    "            print(f\"[Aviso] Arquivos ausentes para modelo {modelo}, experimento {exp_num}.\")\n",
    "            continue\n",
    "\n",
    "        df_unallocated = pd.read_csv(unallocated_file)\n",
    "        df_total = extract_total_requests(log_file)\n",
    "\n",
    "        if time_index is None:\n",
    "            time_index = pd.date_range(start=start_time, periods=len(df_unallocated), freq=freq)\n",
    "\n",
    "        df_unallocated.index = time_index\n",
    "        df_total.index = time_index\n",
    "\n",
    "        dfs_unallocated[modelo] = df_unallocated\n",
    "        dfs_total[modelo] = df_total\n",
    "\n",
    "    if not dfs_unallocated:\n",
    "        print(f\"[Pular] Nenhum dado disponível para cluster {exp_num}\")\n",
    "        return\n",
    "\n",
    "    plt.figure(figsize=(14, 8))\n",
    "\n",
    "    for modelo in dfs_unallocated:\n",
    "        pct_attended = (dfs_total[modelo] - dfs_unallocated[modelo]['Unallocated Requests']) / dfs_total[modelo] * 100\n",
    "        plt.plot(time_index, pct_attended, label=modelo_nomes.get(modelo, modelo), marker='o', alpha=0.6)\n",
    "\n",
    "        # Adiciona ao resumo total de perdas\n",
    "        total_loss = dfs_unallocated[modelo]['Unallocated Requests'].sum()\n",
    "        eventos_perda = (dfs_unallocated[modelo]['Unallocated Requests'] > 0).sum()\n",
    "        tabela_perdas.append({\n",
    "            \"Cluster\": exp_num,\n",
    "            \"Modelo\": modelo_nomes.get(modelo, modelo),\n",
    "            \"Total de Requisições Perdidas\": total_loss,\n",
    "            \"Eventos de Perda\": eventos_perda\n",
    "        })\n",
    "\n",
    "    plt.xlabel(\"Tempo\", fontsize=14)\n",
    "    plt.ylabel(\"Requisições Atendidas (%)\", fontsize=14)\n",
    "    plt.title(f'Cluster {exp_num} - Porcentagem de Requisições Atendidas', fontsize=16)\n",
    "    plt.ylim(0, 105)\n",
    "    plt.grid(True)\n",
    "    plt.legend(fontsize=12)\n",
    "\n",
    "    tick_spacing = len(time_index) // 10\n",
    "    plt.xticks(ticks=time_index[::tick_spacing],\n",
    "               labels=time_index[::tick_spacing].strftime('%Y-%m-%d %H:%M'),\n",
    "               rotation=45, ha='right')\n",
    "\n",
    "    plt.tight_layout()\n",
    "    plt.savefig(f'{output_folder}/Cluster_{exp_num}_attended_comparison.png')\n",
    "    plt.close()\n",
    "\n",
    "# Executa para todos os clusters encontrados\n",
    "for i in exp_nums:\n",
    "    plot_attended_comparison(i)\n",
    "\n",
    "# Exporta a tabela final com perdas\n",
    "df_perdas = pd.DataFrame(tabela_perdas)\n",
    "perdas_csv = os.path.join(output_folder, \"tabela_requisicoes_perdidas_por_cluster.csv\")\n",
    "df_perdas.to_csv(perdas_csv, index=False)\n",
    "\n",
    "print(f\"\\n✅ Gráficos salvos em '{output_folder}' e tabela de perdas salva em:\\n→ {perdas_csv}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "4c417f1a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Relação de erros salva em: relacao_erros_ON_amfs.csv\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import os\n",
    "import re\n",
    "\n",
    "folder = '../output/'\n",
    "file_config = {\n",
    "    \"ON_amfs\": {\n",
    "        \"column_y\": \"ON AMFs\"\n",
    "    }\n",
    "}\n",
    "\n",
    "# Detectar modelos automaticamente a partir dos arquivos (excluindo Ideal)\n",
    "arquivos = os.listdir(folder)\n",
    "modelos_detectados = sorted({f.split('_')[0] for f in arquivos if f.endswith('ON_amfs_log.csv') and not f.startswith('Ideal_')})\n",
    "rotulos = modelos_detectados  # você pode mapear nomes se quiser\n",
    "i_range = sorted({int(f.split('_')[1]) for f in arquivos if f.startswith('Ideal_') and 'ON_amfs' in f})\n",
    "\n",
    "def calcular_erros_apenas(file_config, i_range, modelos):\n",
    "    erros = []\n",
    "\n",
    "    for key, config in file_config.items():\n",
    "        for i in i_range:\n",
    "            arquivos_csv = {\"ideal\": os.path.join(folder, f\"Ideal_{i}_{key}.csv\".replace(\"ON_amfs\", \"ON_amfs_log\"))}\n",
    "            for modelo in modelos:\n",
    "                arquivos_csv[modelo] = os.path.join(folder, f\"{modelo}_{i}_{key}.csv\".replace(\"ON_amfs\", \"ON_amfs_log\"))\n",
    "\n",
    "            dfs = {}\n",
    "            for nome, caminho in arquivos_csv.items():\n",
    "                if os.path.exists(caminho):\n",
    "                    df = pd.read_csv(caminho)\n",
    "                    if config[\"column_y\"] in df.columns:\n",
    "                        dfs[nome] = df\n",
    "                    else:\n",
    "                        print(f\"[Erro] Coluna ausente em {caminho}\")\n",
    "                else:\n",
    "                    print(f\"[Aviso] Arquivo não encontrado: {caminho}\")\n",
    "\n",
    "            if len(dfs) < len(modelos) + 1:\n",
    "                print(f\"[Pular] Cluster {i}: dados incompletos\")\n",
    "                continue\n",
    "\n",
    "            ideal_vals = dfs[\"ideal\"][config[\"column_y\"]].tolist()\n",
    "            min_len = min(len(ideal_vals), *(len(dfs[m][config[\"column_y\"]]) for m in modelos))\n",
    "\n",
    "            for t in range(min_len):\n",
    "                linha_erro = {\n",
    "                    \"Cluster\": i,\n",
    "                    \"Tempo\": t,\n",
    "                    \"Ideal\": ideal_vals[t]\n",
    "                }\n",
    "                for modelo in modelos:\n",
    "                    val = dfs[modelo][config[\"column_y\"]][t]\n",
    "                    erro = val - ideal_vals[t]\n",
    "                    linha_erro[f\"{modelo}\"] = val\n",
    "                    linha_erro[f\"Erro ({modelo})\"] = erro\n",
    "                erros.append(linha_erro)\n",
    "    return pd.DataFrame(erros)\n",
    "\n",
    "# Executar e salvar resultado\n",
    "df_erros = calcular_erros_apenas(file_config, i_range, modelos_detectados)\n",
    "df_erros.to_csv(\"relacao_erros_ON_amfs.csv\", index=False)\n",
    "print(\"Relação de erros salva em: relacao_erros_ON_amfs.csv\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "94be3e25",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Relatório resumido salvo em: relatorio_resumido_erros.csv\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import os\n",
    "import re\n",
    "\n",
    "folder = '../output/'\n",
    "file_config = {\n",
    "    \"ON_amfs\": {\n",
    "        \"column_y\": \"ON AMFs\"\n",
    "    }\n",
    "}\n",
    "\n",
    "# Detectar modelos automaticamente\n",
    "arquivos = os.listdir(folder)\n",
    "modelos_detectados = sorted({f.split('_')[0] for f in arquivos if f.endswith('ON_amfs_log.csv') and not f.startswith('Ideal_')})\n",
    "i_range = sorted({int(f.split('_')[1]) for f in arquivos if f.startswith('Ideal_') and 'ON_amfs' in f})\n",
    "\n",
    "def calcular_erros(file_config, i_range, modelos):\n",
    "    erros = []\n",
    "\n",
    "    for key, config in file_config.items():\n",
    "        for i in i_range:\n",
    "            arquivos_csv = {\"ideal\": os.path.join(folder, f\"Ideal_{i}_{key}.csv\".replace(\"ON_amfs\", \"ON_amfs_log\"))}\n",
    "            for modelo in modelos:\n",
    "                arquivos_csv[modelo] = os.path.join(folder, f\"{modelo}_{i}_{key}.csv\".replace(\"ON_amfs\", \"ON_amfs_log\"))\n",
    "\n",
    "            dfs = {}\n",
    "            for nome, caminho in arquivos_csv.items():\n",
    "                if os.path.exists(caminho):\n",
    "                    df = pd.read_csv(caminho)\n",
    "                    if config[\"column_y\"] in df.columns:\n",
    "                        dfs[nome] = df\n",
    "\n",
    "            if len(dfs) < len(modelos) + 1:\n",
    "                continue\n",
    "\n",
    "            ideal_vals = dfs[\"ideal\"][config[\"column_y\"]].tolist()\n",
    "            min_len = min(len(ideal_vals), *(len(dfs[m][config[\"column_y\"]]) for m in modelos))\n",
    "\n",
    "            for t in range(min_len):\n",
    "                for modelo in modelos:\n",
    "                    val = dfs[modelo][config[\"column_y\"]][t]\n",
    "                    erro = int(round(val - ideal_vals[t]))  # arredondar para contagem\n",
    "                    erros.append({\n",
    "                        \"Cluster\": i,\n",
    "                        \"Modelo\": modelo,\n",
    "                        \"Erro\": erro\n",
    "                    })\n",
    "\n",
    "    return pd.DataFrame(erros)\n",
    "\n",
    "def gerar_relatorio_resumido(df_erros):\n",
    "    relatorio = df_erros.groupby(['Cluster', 'Modelo', 'Erro']).size().unstack(fill_value=0)\n",
    "    relatorio = relatorio.sort_index(axis=1)\n",
    "    return relatorio\n",
    "\n",
    "# Processar\n",
    "df_erros = calcular_erros(file_config, i_range, modelos_detectados)\n",
    "relatorio_resumido = gerar_relatorio_resumido(df_erros)\n",
    "\n",
    "# Salvar\n",
    "relatorio_resumido.to_csv(\"relatorio_resumido_erros.csv\")\n",
    "print(\"Relatório resumido salvo em: relatorio_resumido_erros.csv\")\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "sbrt2025",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.11"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
